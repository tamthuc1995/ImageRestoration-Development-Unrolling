{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3a301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "import itertools\n",
    "import collections\n",
    "import random\n",
    "import time \n",
    "import logging\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import Adam, Adadelta, SGD\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "#########################################################################################################\n",
    "torch.set_float32_matmul_precision('high')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT_PROJECT = \"/home/jovyan/shared/Thuc/hoodsgatedrive/projects/ImageRestoration-Development-Unrolling/\"\n",
    "ROOT_DATASET = \"/home/jovyan/shared/Thuc/hoodsgatedrive/projects/\"\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "sys.path.append(os.path.join(ROOT_PROJECT, 'exploration/model_multiscale_mixture_GLR/lib'))\n",
    "from dataloader import ImageSuperResolution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc17f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909ad175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LOG_DIR = os.path.join(ROOT_PROJECT, \"exploration/model_multiscale_mixture_GLR/result/model_test11/logs/\")\n",
    "LOGGER = logging.getLogger(\"main\")\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s: %(message)s', \n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "    filename=os.path.join(LOG_DIR, 'training00.log'), \n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(ROOT_PROJECT, \"exploration/model_multiscale_mixture_GLR/result/model_test11/checkpoints/\")\n",
    "VERBOSE_RATE = 1000\n",
    "\n",
    "(H_train, W_train) = (128, 128)\n",
    "(H_val, W_val) = (128, 128)\n",
    "(H_test, W_test) = (496, 496)\n",
    "\n",
    "train_dataset = ImageSuperResolution(\n",
    "    csv_path=os.path.join(ROOT_DATASET, \"dataset/DFWB_training_data_info.csv\"),\n",
    "    dist_mode=\"addictive_noise_scale\",\n",
    "    lambda_noise=25.0,\n",
    "    patch_size=H_train,\n",
    "    patch_overlap_size=H_train//2,\n",
    "    max_num_patchs=1000000,\n",
    "    root_folder=ROOT_DATASET,\n",
    "    logger=LOGGER,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "validation_dataset = ImageSuperResolution(\n",
    "    csv_path=os.path.join(ROOT_DATASET, \"dataset/CBSD68_testing_data_info.csv\"),\n",
    "    dist_mode=\"addictive_noise_scale\",\n",
    "    lambda_noise=25.0,\n",
    "    patch_size=H_val,\n",
    "    patch_overlap_size=H_train//2,\n",
    "    max_num_patchs=1000000,\n",
    "    root_folder=ROOT_DATASET,\n",
    "    logger=LOGGER,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "test_dataset = ImageSuperResolution(\n",
    "    csv_path=os.path.join(ROOT_DATASET, \"dataset/McMaster_testing_data_info.csv\"),\n",
    "    dist_mode=\"addictive_noise_scale\",\n",
    "    lambda_noise=25.0,\n",
    "    patch_size=H_test,\n",
    "    patch_overlap_size=H_train//2,\n",
    "    max_num_patchs=1000000,\n",
    "    root_folder=ROOT_DATASET,\n",
    "    logger=LOGGER,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "\n",
    "data_train_batched = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=4, num_workers=4\n",
    ")\n",
    "\n",
    "data_valid_batched = torch.utils.data.DataLoader(\n",
    "    validation_dataset, batch_size=16, num_workers=4\n",
    ")\n",
    "\n",
    "data_test_batched = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b47b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size,\n",
    "        padding=(kernel_size//2), bias=bias)\n",
    "\n",
    "class MeanShift(nn.Conv2d):\n",
    "    def __init__(\n",
    "        self, rgb_range,\n",
    "        rgb_mean=(0.4488, 0.4371, 0.4040), rgb_std=(1.0, 1.0, 1.0), sign=-1):\n",
    "\n",
    "        super(MeanShift, self).__init__(3, 3, kernel_size=1)\n",
    "        std = torch.Tensor(rgb_std)\n",
    "        self.weight.data = torch.eye(3).view(3, 3, 1, 1) / std.view(3, 1, 1, 1)\n",
    "        self.bias.data = sign * rgb_range * torch.Tensor(rgb_mean) / std\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "class BasicBlock(nn.Sequential):\n",
    "    def __init__(\n",
    "        self, conv, in_channels, out_channels, kernel_size, stride=1, bias=False,\n",
    "        bn=True, act=nn.ReLU(True)):\n",
    "\n",
    "        m = [conv(in_channels, out_channels, kernel_size, bias=bias)]\n",
    "        if bn:\n",
    "            m.append(nn.BatchNorm2d(out_channels))\n",
    "        if act is not None:\n",
    "            m.append(act)\n",
    "\n",
    "        super(BasicBlock, self).__init__(*m)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, conv, n_feats, kernel_size,\n",
    "        bias=True, bn=False, act=nn.ReLU(True), res_scale=1):\n",
    "\n",
    "        super(ResBlock, self).__init__()\n",
    "        m = []\n",
    "        for i in range(2):\n",
    "            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feats))\n",
    "            if i == 0:\n",
    "                m.append(act)\n",
    "\n",
    "        self.body = nn.Sequential(*m)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.body(x).mul(self.res_scale)\n",
    "        res += x\n",
    "\n",
    "        return res\n",
    "\n",
    "class Upsampler(nn.Sequential):\n",
    "    def __init__(self, conv, scale, n_feats, bn=False, act=False, bias=True):\n",
    "\n",
    "        m = []\n",
    "        if (scale & (scale - 1)) == 0:    # Is scale = 2^n?\n",
    "            for _ in range(int(math.log(scale, 2))):\n",
    "                m.append(conv(n_feats, 4 * n_feats, 3, bias))\n",
    "                m.append(nn.PixelShuffle(2))\n",
    "                if bn:\n",
    "                    m.append(nn.BatchNorm2d(n_feats))\n",
    "                if act == 'relu':\n",
    "                    m.append(nn.ReLU(True))\n",
    "                elif act == 'prelu':\n",
    "                    m.append(nn.PReLU(n_feats))\n",
    "\n",
    "        elif scale == 3:\n",
    "            m.append(conv(n_feats, 9 * n_feats, 3, bias))\n",
    "            m.append(nn.PixelShuffle(3))\n",
    "            if bn:\n",
    "                m.append(nn.BatchNorm2d(n_feats))\n",
    "            if act == 'relu':\n",
    "                m.append(nn.ReLU(True))\n",
    "            elif act == 'prelu':\n",
    "                m.append(nn.PReLU(n_feats))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        super(Upsampler, self).__init__(*m)\n",
    "\n",
    "\n",
    "\n",
    "class MDSR(nn.Module):\n",
    "    def __init__(self, args, conv=default_conv):\n",
    "        super(MDSR, self).__init__()\n",
    "        n_resblocks = args[\"n_resblocks\"]\n",
    "        n_feats = args[\"n_feats\"]\n",
    "        kernel_size = 3\n",
    "        act = nn.ReLU(True)\n",
    "        self.scale_idx = 0\n",
    "        self.sub_mean = MeanShift(args[\"rgb_range\"])\n",
    "        self.add_mean = MeanShift(args[\"rgb_range\"], sign=1)\n",
    "\n",
    "        m_head = [conv(args[\"n_colors\"], n_feats, kernel_size)]\n",
    "\n",
    "        self.pre_process = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                ResBlock(conv, n_feats, 5, act=act),\n",
    "                ResBlock(conv, n_feats, 5, act=act)\n",
    "            ) for _ in args[\"scale\"]\n",
    "        ])\n",
    "\n",
    "        m_body = [\n",
    "            ResBlock(\n",
    "                conv, n_feats, kernel_size, act=act\n",
    "            ) for _ in range(n_resblocks)\n",
    "        ]\n",
    "        m_body.append(conv(n_feats, n_feats, kernel_size))\n",
    "\n",
    "        self.upsample = nn.ModuleList([\n",
    "            Upsampler(conv, int(s), n_feats, act=False) for s in args[\"scale\"]\n",
    "        ])\n",
    "\n",
    "        m_tail = [conv(n_feats, args[\"n_colors\"], kernel_size)]\n",
    "\n",
    "        self.head = nn.Sequential(*m_head)\n",
    "        self.body = nn.Sequential(*m_body)\n",
    "        self.tail = nn.Sequential(*m_tail)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sub_mean(x)\n",
    "        x = self.head(x)\n",
    "        x = self.pre_process[self.scale_idx](x)\n",
    "\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "\n",
    "        x = self.upsample[self.scale_idx](res)\n",
    "        x = self.tail(x)\n",
    "        x = self.add_mean(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_scale(self, scale_idx):\n",
    "        self.scale_idx = scale_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf92236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d4212ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDSR(\n",
       "  (sub_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (add_mean): MeanShift(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (pre_process): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ResBlock(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upsample): ModuleList(\n",
       "    (0): Upsampler()\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (11): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (12): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (13): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (14): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (15): ResBlock(\n",
       "      (body): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (tail): Sequential(\n",
       "    (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MDSR({\n",
    "    \"n_resblocks\":16,\n",
    "    \"n_feats\": 64,\n",
    "    \"rgb_range\": 255,\n",
    "    \"n_colors\": 3,\n",
    "    \"scale\": \"1\"\n",
    "}).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff413baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_test_noisy, img_test_clean in data_test_batched:\n",
    "\n",
    "    img_test_noisy = img_test_noisy.to(DEVICE)\n",
    "    img_test_clean = img_test_clean.to(DEVICE) \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4ff2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(img_test_noisy.permute(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59cea7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 496, 496])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25ee844a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 496, 496, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_test_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b647e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1984 / 496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "import itertools\n",
    "import collections\n",
    "import random\n",
    "import time \n",
    "import logging\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "#########################################################################################################\n",
    "torch.set_float32_matmul_precision('high')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT_PROJECT = \"/home/jovyan/shared/Thuc/hoodsgatedrive/projects/ImageRestoration-Development-Unrolling/\"\n",
    "ROOT_DATASET = \"/home/jovyan/shared/Thuc/hoodsgatedrive/projects/\"\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "sys.path.append(os.path.join(ROOT_PROJECT, 'exploration/model_multiscale_mixture_GLR/lib'))\n",
    "from dataloader import ImageSuperResolution\n",
    "import baselineRestormer as model_structure\n",
    "\n",
    "\n",
    "LOG_DIR = os.path.join(ROOT_PROJECT, \"exploration/model_multiscale_mixture_GLR/result/model_test_unet/logs/\")\n",
    "LOGGER = logging.getLogger(\"main\")\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s: %(message)s', \n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "    filename=os.path.join(LOG_DIR, 'training00.log'), \n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(ROOT_PROJECT, \"exploration/model_multiscale_mixture_GLR/result/model_test_unet/checkpoints/\")\n",
    "VERBOSE_RATE = 1000\n",
    "\n",
    "(H_train, W_train) = (128, 128)\n",
    "(H_val, W_val) = (128, 128)\n",
    "(H_test, W_test) = (496, 496)\n",
    "\n",
    "train_dataset = ImageSuperResolution(\n",
    "    csv_path=os.path.join(ROOT_DATASET, \"dataset/DFWB_training_data_info.csv\"),\n",
    "    dist_mode=\"addictive_noise_scale\",\n",
    "    lambda_noise=25.0,\n",
    "    patch_size=H_train,\n",
    "    patch_overlap_size=H_train//2,\n",
    "    max_num_patchs=1000000,\n",
    "    root_folder=ROOT_DATASET,\n",
    "    logger=LOGGER,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "validation_dataset = ImageSuperResolution(\n",
    "    csv_path=os.path.join(ROOT_DATASET, \"dataset/CBSD68_testing_data_info.csv\"),\n",
    "    dist_mode=\"addictive_noise\",\n",
    "    lambda_noise=25.0,\n",
    "    patch_size=H_val,\n",
    "    patch_overlap_size=H_train//2,\n",
    "    max_num_patchs=1000000,\n",
    "    root_folder=ROOT_DATASET,\n",
    "    logger=LOGGER,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "test_dataset = ImageSuperResolution(\n",
    "    csv_path=os.path.join(ROOT_DATASET, \"dataset/McMaster_testing_data_info.csv\"),\n",
    "    dist_mode=\"addictive_noise\",\n",
    "    lambda_noise=25.0,\n",
    "    patch_size=H_test,\n",
    "    patch_overlap_size=0,\n",
    "    max_num_patchs=1000000,\n",
    "    root_folder=ROOT_DATASET,\n",
    "    logger=LOGGER,\n",
    "    device=torch.device(\"cpu\"),\n",
    ")\n",
    "\n",
    "\n",
    "data_train_batched = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=4, num_workers=4\n",
    ")\n",
    "\n",
    "data_valid_batched = torch.utils.data.DataLoader(\n",
    "    validation_dataset, batch_size=16, num_workers=4\n",
    ")\n",
    "\n",
    "data_test_batched = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, num_workers=4\n",
    ")\n",
    "\n",
    "NUM_EPOCHS = 45\n",
    "\n",
    "CONNECTION_FLAGS = np.array([\n",
    "    1,1,1,\n",
    "    1,0,1,\n",
    "    1,1,1,\n",
    "]).reshape((3,3))\n",
    "\n",
    "\n",
    "model = model_structure.Restormer(**{\n",
    "    \"inp_channels\":3, \n",
    "    \"out_channels\":3, \n",
    "    \"dim\": 48,\n",
    "    \"num_blocks\": [4,6,6,8], \n",
    "    \"num_refinement_blocks\": 4,\n",
    "    \"heads\": [1,2,4,8],\n",
    "    \"ffn_expansion_factor\": 2.66,\n",
    "    \"bias\": False,\n",
    "    \"LayerNorm_type\": 'BiasFree',   ## Other option 'BiasFree'\n",
    "    \"dual_pixel_task\": False        ## True for dual-pixel defocus deblurring only. Also set inp_channels=6\n",
    "}).to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92504aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = 0\n",
    "for p in model.parameters():\n",
    "    s += np.prod(np.array(p.shape))\n",
    "    # print(p.dtype, np.array(p.shape), s)\n",
    "\n",
    "LOGGER.info(f\"Init model with total parameters: {s}\")\n",
    "\n",
    "criterian = nn.L1Loss()\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0003,\n",
    "    eps=1e-08\n",
    ")\n",
    "\n",
    "### TRAINING\n",
    "LOGGER.info(\"######################################################################################\")\n",
    "LOGGER.info(\"BEGIN TRAINING PROCESS\")\n",
    "# training_state_path = os.path.join(CHECKPOINT_DIR, 'checkpoints_epoch00_iter0024k.pt')\n",
    "# training_state = torch.load(training_state_path)\n",
    "# model.load_state_dict(training_state[\"model\"])\n",
    "# optimizer.load_state_dict(training_state[\"optimizer\"])\n",
    "# i_checkpoint=training_state[\"i\"]\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    i = 0\n",
    "    ### TRAINING\n",
    "    for patchs_noisy, patchs_true in data_train_batched:\n",
    "        s = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        patchs_noisy = patchs_noisy.to(DEVICE)\n",
    "        patchs_true = patchs_true.to(DEVICE) \n",
    "        reconstruct_patchs = model(patchs_noisy.permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "        loss_value = criterian(reconstruct_patchs, patchs_true)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        img_true = np.clip(patchs_true.detach().cpu().numpy(), a_min=0.0, a_max=1.0).astype(np.float64)\n",
    "        img_recon = np.clip(reconstruct_patchs.detach().cpu().numpy(), a_min=0.0, a_max=1.0).astype(np.float64)\n",
    "        train_mse_value = np.square(img_true- img_recon).mean()\n",
    "        train_psnr = 10 * np.log10(1/train_mse_value)\n",
    "        LOGGER.info(f\"iter={i} time={time.time()-s} psnr={train_psnr} mse={train_mse_value}\")\n",
    "\n",
    "        if (i%VERBOSE_RATE == 0):\n",
    "            checkpoint = { \n",
    "                'i': i,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(checkpoint, os.path.join(CHECKPOINT_DIR, f'checkpoints_epoch{str(epoch).zfill(2)}_iter{str(i//VERBOSE_RATE).zfill(4)}k.pt'))\n",
    "\n",
    "\n",
    "        if (i%(VERBOSE_RATE/5) == 0):\n",
    "            # LOGGER.info(f\"Start VALIDATION EPOCH {epoch} - iter={i}\")\n",
    "            # model.graph_frame_recalibrate(H_val, W_val)\n",
    "\n",
    "            # ### VALIDAING\n",
    "            model.eval()\n",
    "            list_val_mse = []\n",
    "            val_i = 0\n",
    "            for val_patchs_noisy, val_patchs_true in data_valid_batched:\n",
    "                s = time.time()\n",
    "                with torch.no_grad():\n",
    "                    val_patchs_noisy = val_patchs_noisy.to(DEVICE)\n",
    "                    val_patchs_true = val_patchs_true.to(DEVICE) \n",
    "\n",
    "                    reconstruct_patchs = model(val_patchs_noisy.permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "                    img_true = np.clip(val_patchs_true.cpu().numpy(), a_min=0.0, a_max=1.0).astype(np.float64)\n",
    "                    img_recon = np.clip(reconstruct_patchs.cpu().numpy(), a_min=0.0, a_max=1.0).astype(np.float64)\n",
    "                    val_mse_value = np.square(img_true- img_recon).mean()\n",
    "                    list_val_mse.append(val_mse_value)\n",
    "                    # LOGGER.info(f\"test_i={test_i} time={time.time()-s} test_i_psnr_value={10 * np.log10(1/test_mse_value)}\")\n",
    "                val_i+=1\n",
    "\n",
    "            psnr_validation = 10 * np.log10(1/np.array(list_val_mse))\n",
    "            LOGGER.info(f\"FINISH VALIDATION EPOCH {epoch} - iter={i} -  psnr_validation={np.mean(psnr_validation)}\")\n",
    "            # model.graph_frame_recalibrate(H_train, W_train)\n",
    "            model.train()\n",
    "\n",
    "        if (i%VERBOSE_RATE == 0):\n",
    "\n",
    "            # LOGGER.info(f\"Start VALIDATION EPOCH {epoch} - iter={i}\")\n",
    "            # model.graph_frame_recalibrate(H_test, W_test)\n",
    "\n",
    "            # ### VALIDAING\n",
    "            model.eval()\n",
    "            list_test_mse = []\n",
    "            test_i = 0\n",
    "            for test_patchs_noisy, test_patchs_true in data_test_batched:\n",
    "                s = time.time()\n",
    "                with torch.no_grad():\n",
    "                    test_patchs_noisy = test_patchs_noisy.to(DEVICE)\n",
    "                    test_patchs_true = test_patchs_true.to(DEVICE) \n",
    "                    reconstruct_patchs = model(test_patchs_noisy.permute(0, 3, 1, 2)).permute(0, 2, 3, 1)\n",
    "                    img_true = np.clip(test_patchs_true[0].cpu().numpy(), a_min=0.0, a_max=1.0).astype(np.float64)\n",
    "                    img_recon = np.clip(reconstruct_patchs[0].cpu().numpy(), a_min=0.0, a_max=1.0).astype(np.float64)\n",
    "                    test_mse_value = np.square(img_true- img_recon).mean()\n",
    "                    list_test_mse.append(test_mse_value)\n",
    "                    # LOGGER.info(f\"test_i={test_i} time={time.time()-s} test_i_psnr_value={10 * np.log10(1/test_mse_value)}\")\n",
    "                test_i+=1\n",
    "\n",
    "            psnr_testing = 10 * np.log10(1/np.array(list_test_mse))\n",
    "            LOGGER.info(f\"FINISH TESING EPOCH {epoch} - iter={i} -  psnr_testing={np.mean(psnr_testing)}\")\n",
    "            # model.graph_frame_recalibrate(H_train, W_train)\n",
    "            model.train()\n",
    "\n",
    "        i+=1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d842b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
